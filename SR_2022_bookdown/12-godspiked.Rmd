# God spiked the integers

GLMs are complex machines that are hard to interpret without understanding the whole and each of the parts within. To get started on trying to understand GLMs, we will look at count data (0, 1, 2, ... etc).

Binomial regression will be when we have 2 defined outcomes that are both measured. (alive/dead, accept/reject)

Poisson regression is for counts that have no known maximum (number of animals in a country) or:

>>number of significance tests in an issue of *Psychological Science*. (p. 323)\

## Binomial regression

Going waaaay back to the globe tossing model

$$y \sim \text{Binomial}(n, p)$$
here $y$ is the count (0 or positive whole number), $p$ is the probability any 'trial' is a success, and $n$ is the number of trials. For the binomial to work we must have a constant expected value.

There are 2 common GLMs for Binomials\
1. Logistic regression - independent outcomes are 0 or 1\
2. Aggregated Binomial Regression - samilar covariate trials are grouped\

Both of the above will make use of the Logit link function

### Logistic regression : Prosocial chimpanzees

EXPERIMENT:\
chimps can use levers to move food items on a table. The left lever will bring the left food item closer and the right lever will move the right food item closer. This is mirrored across the table but there is only one food item in either the left or the right (not both).

Condition one (control): There is not another chimp across the table. empty social food item will randomly switch from left to right

Condition two: there is another chimp across the table. Choosing to move the side with the social food item is counted as prosocial. choosing to move the empty social food dish is anti-social. Again left and right for the social dish is random.

```{r}
#library(rethinking)
data(chimpanzees)
d <- chimpanzees
```

We are going to count `pulled_left` ($y$) predicted by `prosoc_left` and `condition`. There are four combinations:\

```{r}
number <- 1:4
prosocial_left <- c(0,1,0,1)
condition <- c(0,0,1,1)
description <- c("Two food items on the right and no partner",
                 "Two food items on the left and no partner",
                 "Two food items on the right and partner present",
                 "Two food items on the left and partner present")
experiment <- cbind(number, prosocial_left, condition, description)

knitr::kable(experiment, "html")
```

Now we can make an index to match each of the 4 outcomes above
```{r}
d$treatment <- 1 + d$prosoc_left + 2*d$condition
```

verify it worked
```{r}
xtabs(~treatment + prosoc_left + condition, data = d)
```

Now lets build the model
$$L_{i} \sim \text{Binomial}(1, p_{i})\\
\text{logit}(p_{i}) = \alpha_{ACTOR[i]} + \beta_{TREATMENT[i]}\\
\alpha_{j} \sim \text{TBD}\\
\beta_{k} \sim \text{TBD}$$

So $L$ is whether the left lever was pulled. $\alpha$ has 7 parameters (for 7 chimps) and $\beta$ we know has 4 parameters for treatments. 

Now we can go ahead and try to define the priors for our model. We can start conservative
$$L_{i} \sim \text{Binomial}(1, p_{i})\\
\text{logit}(p_{i}) = \alpha\\
\alpha \sim \text{Normal}(0, \omega)$$

we will start with a flat prior where $\omega$ is 10
```{r}
m11.1 <- quap(
  alist(
    pulled_left ~ dbinom(1, p),
    logit(p) <- a,
    a ~ dnorm(0, 10)
  ), data = d
)
```

and sample the prior
```{r}
set.seed(11)
prior <- extract.prior(m11.1, n=1e4)
```

now we transform the logit to probability space
```{r}
p <- inv_logit(prior$a)
dens(p, adj = 0.1)
```

So the model (before seeing data) thinks that either its always the left lever or never the left lever.
```{r}
m11.1 <- quap(
  alist(
    pulled_left ~ dbinom(1, p),
    logit(p) <- a,
    a ~ dnorm(0, 1.5)
  ), data = d
)

set.seed(11)
prior <- extract.prior(m11.1, n=1e4)

p2 <- inv_logit(prior$a)
dens(c(p2), adj = 0.1, col=c('black', rangi2))
```

```{r}
m11.2 <- quap(
  alist(
    pulled_left ~ dbinom(1, p),
    logit(p) <- a + b[treatment],
    a ~ dnorm(0, 1.5),
    b[treatment] ~ dnorm(0,10)
  ), data = d
)

set.seed(11)
prior <- extract.prior(m11.2, n = 1e4)

p <- sapply(1:4, function(k) inv_logit(prior$a + prior$b[,k]))
```

`p` now holds the prior probability for each of the 4 treatments. Let's investigate the difference between the first two
```{r}
dens(abs(p[,1]-p[,2]), adj = 0.1)
```

So now the model thinks that these two treatments are either the same, or completely different. Let's tighten it up.
```{r}
m11.3 <- quap(
  alist(
    pulled_left ~ dbinom(1, p),
    logit(p) <- a + b[treatment],
    a ~ dnorm(0, 1.5),
    b[treatment] ~ dnorm(0,0.5)
  ), data = d
)

set.seed(11)
prior <- extract.prior(m11.3, n = 1e4)

p <- sapply(1:4, function(k) inv_logit(prior$a + prior$b[,k]))

mean(abs(p[,1] - p[,2]))

dens(abs(p[,1]-p[,2]), adj = 0.1)
```

Now the model finds them rather similar with a mean difference of about 10%.

Great, now lets get ready for HMC
```{r}
#trimmed data list
dat_list <- list(
  pulled_left = d$pulled_left,
  actor = d$actor,
  treatment = as.integer(d$treatment)
)

m11.4 <- ulam(
  alist(
    pulled_left ~ dbinom(1, p),
    logit(p) <- a[actor] + b[treatment],
    a[actor] ~ dnorm(0, 1.5),
    b[treatment] ~ dnorm(0, 0.5)
  ), data = dat_list, chains = 4, log_lik = TRUE
)

precis(m11.4, depth = 2)
```

What? Yeah, me too. Let's break this down.
```{r}
post <- extract.samples(m11.4)
p_left <- inv_logit(post$a)
precis_plot(precis(as.data.frame(p_left)), xlim = c(0,1))
```

Here each row is a chimpanzee and you can see most actually preferred the right lever. One chimp really liked the left lever. This tells us left or right, but how do we know if they were being prosocial?

```{r}
labs <- c("R/N", "L/N", "R/P", "L/P")
precis_plot(precis(m11.4, depth = 2, pars = "b"), labels = labs) 
```

These coefficients are still in logit space so don't take them at face value for each treatment yet. Let's contrast the Right side and the Left side to see if the coefficients are very different.

```{r}
diffs <- list(
  db13 = post$b[,1] - post$b[,3],
  db24 = post$b[,2] - post$b[,4]
)
precis_plot(precis(diffs))
```

So now we are looking at the difference between the no partner/partner on the right (db13) and left sides (db24). The right has a bit of a stronger 'prosocial' signal but not important as they both have large intervals.

Now we can try a posterior predictive check. Let's calculate the proportion of left pulls for each actor in each treatment and see how it matches the posterior.
```{r}
pl <- by(d$pulled_left, list(d$actor, d$treatment), mean)
pl[1,]
```

Now we can use these observed proportions and compare them to the models predictions for each combination of actor and treatment.

```{r}
dat <- list(actor = rep(1:7, each=4), treatment = rep(1:4, times = 7))
p_post <- link(m11.4, data = dat)
p_mu <- apply(p_post, 2, mean)
p_ci <- apply(p_post, 2, PI)
```

And we can plot to see how well our model predicts the data
```{r}
par(mfrow=c(2,1))
#observations
plot( NULL,xlim=c(1,28),ylim=c(0,1),xlab="",
ylab="proportion left lever",xaxt="n",yaxt="n")
axis( 2,at=c(0,0.5,1),labels=c(0,0.5,1))
abline( h=0.5,lty=2)
for (j in 1:7)abline(v=(j-1)*4+4.5,lwd=0.5)
for (j in 1:7)text((j-1)*4+2.5,1.1,concat("actor",j),xpd=TRUE)
for (j in (1:7)[-2]){
lines( (j-1)*4+c(1,3),pl[j,c(1,3)],lwd=2,col=rangi2)
lines( (j-1)*4+c(2,4),pl[j,c(2,4)],lwd=2,col=rangi2)
}
points( 1:28,t(pl),pch=16,col="white",cex=1.7)
points( 1:28,t(pl),pch=c(1,1,16,16),col=rangi2,lwd=2)
yoff <-0.01
text( 1,pl[1,1]-yoff,"R/N",pos=1,cex=0.8)
text( 2,pl[1,2]+yoff,"L/N",pos=3,cex=0.8)
text( 3,pl[1,3]-yoff,"R/P",pos=1,cex=0.8)
text( 4,pl[1,4]+yoff,"L/P",pos=3,cex=0.8)
mtext( "observed proportions\n")

##prediction plot
plot( NULL,xlim=c(1,28),ylim=c(0,1),xlab="",
ylab="proportion left lever",xaxt="n",yaxt="n")
axis( 2,at=c(0,0.5,1),labels=c(0,0.5,1))
abline( h=0.5,lty=2)
for (j in 1:7)abline(v=(j-1)*4+4.5,lwd=0.5)
for (j in 1:7)text((j-1)*4+2.5,1.1,concat("actor",j),xpd=TRUE)
for (j in (1:7)[-2]){
lines( (j-1)*4+c(1,3),p_mu[c( ((4*j)-3), ((4*j)-1) )],lwd=2,col='black')
lines( (j-1)*4+c(2,4),p_mu[c( ((4*j)-2), (4*j) )],lwd=2,col='black')
}

for (j in (1:7)[-2]){
lines( (j-1)*4+c(1,1) ,p_ci[c(1,2), ((4*j)-3)],lwd=2,col='black')
lines( (j-1)*4+c(3,3) ,p_ci[c(1,2), ((4*j)-1)],lwd=2,col='black')
lines( (j-1)*4+c(2,2) ,p_ci[c(1,2), ((4*j)-2)],lwd=2,col='black')
lines( (j-1)*4+c(4,4) ,p_ci[c(1,2), (4*j)],lwd=2,col='black')

}

points( 1:28,t(p_mu),pch=16,col="white",cex=1.7)
points( 1:28,t(p_mu),pch=c(1,1,16,16),col='black',lwd=2)
mtext( "posterior predictions\n")

```

Now we see that there is almost no expected change from the model between partner present or absent. Also, there doesn't appear to be any affect of left vs right. But we could always check

```{r}
d$side <- d$prosoc_left + 1 #right = 1, left = 2
d$cond <- d$condition + 1 #no partner = 1, partner = 2
```

```{r}
dat_list2 <- list(
  pulled_left = d$pulled_left,
  actor = d$actor,
  side = d$side,
  cond = d$cond
)

m11.5 <- ulam(
  alist(
    pulled_left ~ dbinom(1, p),
    logit(p) <- a[actor] + bs[side] + bc[cond],
    a[actor] ~ dnorm(0, 1.5),
    bs[side] ~ dnorm(0, 0.5),
    bc[cond] ~ dnorm(0, 0.5)
  ), data = dat_list2, chains = 4, log_lik = TRUE
)
```
and then we can compare with PSIS
```{r}
compare(m11.5, m11.4, func=PSIS)
```

### Relative shark and absolute deer

What was described above was the absolute effect on the outcome. We can also calculate the relative effects or proportional odds. Here is the switch from treatment 2 $\rightarrow$ 4 (adding a partner, left side food).
```{r}
post <- extract.samples(m11.4)
mean(exp(post$b[,4]-post$b[,2])) 
```

So we would multiply the odds of pulling the left lever by 0.92 which is a 8% reduction in pulling the left lever. This isn't enough to make any big picture inferences though. 

### Aggregated binomial: Chimps condensed

Now we can analyze the data with the sets of variables aggregated or group in similar scenarios. Like how many left hand pulls across all trials
```{r}
data(chimapnzees)
d <- chimpanzees
d$treatment <- 1 + d$prosoc_left + 2*d$condition
d$side <- d$prosoc_left + 1 #right 1, left 2
d$cond <- d$condition + 1 # no partner 1, partner 2
d_aggregated <- aggregate(
  d$pulled_left, list(
    treatment = d$treatment, actor = d$actor, side = d$side, cond = d$cond
  ), sum
)
colnames(d_aggregated)[5] <- "left_pulls"
```

Now we can use the aggregated data to get the same results
```{r}
dat <- with(d_aggregated, list(
  left_pulls = left_pulls,
  treatment = treatment,
  actor = actor,
  cond = cond
))

m11.6 <- ulam(
  alist(
    left_pulls ~ dbinom(18, p),
    logit(p) <- a[actor] + b[treatment],
    a[actor] ~ dnorm(0, 1.5),
    b[treatment] ~ dnorm(0, 0.5)
  ), data = dat, chains = 4, log_lik = TRUE
)

compare(m11.6, m11.4, func=PSIS)
```

The distribution of the aggregated data is larger because the model knows the total number of trials and the number of successes. Here is a comparison of 6 successes in 9 trials aggregated vs unaggregated
```{r}
#deviance of aggregate
-2*dbinom(6, 9, 0.2, log = TRUE)
#deviance of unaggregated
-2*sum(dbern(c(1,1,1,1,1,1,0,0,0), 0.2, log = TRUE))
```

This doesn't mean anything for the posterior though. It will be the same across the two methods. If you are interested in the output of WAIC of PSIS, you should use the unaggregated model.

### Aggregated admissions

```{r}
data(UCBadmit)
d <- UCBadmit
d
```

Is there gender bias?
$$A_{i} \sim \text{Binomial}(N_{i}, p_{i})\\
\text{logit}(p_{i}) = \alpha_{GID[i]}\\
\alpha_{j} \sim \text{Normal}(0, 1.5)$$

```{r}
dat_list <- list(
  admit = d$admit,
  applications = d$applications,
  gid = ifelse(d$applicant.gender == "male", 1, 2)
)

m11.7 <- ulam(
  alist(
    admit ~ dbinom(applications, p),
    logit(p) <- a[gid],
    a[gid] ~ dnorm(0, 1.5)
  ), data = dat_list, chains = 4
)

precis(m11.7, depth = 2)
```

```{r}
post <- extract.samples(m11.7)
diff_a <- post$a[,1] - post$a[,2]
diff_p <- inv_logit(post$a[,1]) - inv_logit(post$a[,2])
precis(list(diff_a=diff_a, diff_p=diff_p))
```

The log-odds difference (`diff_a`) is positive which indicates a higher admit prob for males. the outcome probability is 12-16% higher for males.

Visualize the posterior
```{r}
postcheck(m11.7)
for(i in 1:6){
  x <- 1 + 2*(i-1)
  y1 <- d$admit[x]/d$applications[x]
  y2 <- d$admit[x+1]/d$applications[x+1]
  lines(c(x, x+1), c(y1, y2), col=rangi2, lwd=2)
  text(x+0.5, (y1+y2)/2 + 0.05, d$dept[x], cex = 0.8, col=rangi2)
}
```

Women overall have less probability of getting admitted, but there is within deparrtment variation. Let's account for this

$$A_{i} \sim \text{Binomial}(N_{i}, p_{i})\\
\text{logit}(p_{i}) = \alpha_{GID[i]} + \delta_{DEPT[i]}\\
\alpha_{j} \sim \text{Normal}(0, 1.5)\\
\delta_{k} \sim \text{Normal}(0, 1.5)$$

```{r}
dat_list$dept_id <- rep(1:6, each = 2)
m11.8 <- ulam(
  alist(
    admit ~ dbinom(applications, p),
    logit(p) <- a[gid] + delta[dept_id],
    a[gid] ~ dnorm(0, 1.5),
    delta[dept_id] ~ dnorm(0, 1.5)
  ), data = dat_list, chains = 4, iter = 4000
)

precis(m11.8, depth = 2)
```

```{r}
post <- extract.samples(m11.8)
diff_a <- post$a[,1] - post$a[,2]
diff_p <- inv_logit(post$a[,1]) - inv_logit(post$a[,2])
precis(list(diff_a=diff_a, diff_p=diff_p))

```

So within departments males actually have a tiny 2% reduction in admission probability.

```{r}
pg <- with(dat_list, sapply(1:6, function(k) applications[dept_id==k]/sum(applications[dept_id==k])))
rownames(pg) <- c("male", "female")
colnames(pg) <- unique(d$dept)
round(pg,2)
```

```{r}
postcheck(m11.8)
```

##Poisson regression

